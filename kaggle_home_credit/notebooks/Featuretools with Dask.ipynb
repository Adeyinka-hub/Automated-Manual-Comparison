{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will develop a function to perform dfs from an existing entityset. This reads in the entityset, creates the seed features and the interesting values, and then runs deep feature synthesis on the entityset. This code is specific to the Home Credit competition (for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# featuretools for automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and format\n",
    "\n",
    "First, we read in the data, correcting the anomalies by setting them equal to `np.nan`. Then we join together the training and testing data into `app`. When we define relationships, the indexes must be the same data type. For some reason, that is not initially the case, so we reassign all the indexes as `np.int64` type. Finally, we put the `SK_ID_CURR` in `bureau_balance` so we can use that for partioning data and set `SK_ID_CURR` as the index in all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets and replace the anomalous values\n",
    "app_train = pd.read_csv('../input/application_train.csv').replace({365243: np.nan})\n",
    "app_test = pd.read_csv('../input/application_test.csv').replace({365243: np.nan})\n",
    "bureau = pd.read_csv('../input/bureau.csv').replace({365243: np.nan})\n",
    "bureau_balance = pd.read_csv('../input/bureau_balance.csv').replace({365243: np.nan})\n",
    "cash = pd.read_csv('../input/POS_CASH_balance.csv').replace({365243: np.nan})\n",
    "credit = pd.read_csv('../input/credit_card_balance.csv').replace({365243: np.nan})\n",
    "previous = pd.read_csv('../input/previous_application.csv').replace({365243: np.nan})\n",
    "installments = pd.read_csv('../input/installments_payments.csv').replace({365243: np.nan})\n",
    "\n",
    "app_test['TARGET'] = np.nan\n",
    "\n",
    "# Join together training and testing\n",
    "app = app_train.append(app_test, ignore_index = True, sort = True)\n",
    "\n",
    "# All ids should be integers\n",
    "for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "    for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "        if index in list(dataset.columns):\n",
    "            # Convert to integers after filling in missing values (not sure why values are missing)\n",
    "            dataset[index] = dataset[index].fillna(0).astype(np.int64)\n",
    "\n",
    "# Need `SK_ID_CURR` in every dataset\n",
    "bureau_balance = bureau_balance.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], \n",
    "                                      on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "\n",
    "# Set the index for locating\n",
    "for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "    dataset.set_index('SK_ID_CURR', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in Feature names\n",
    "\n",
    "We already calculated the feature names, so it's simple to read them in. This avoids the need to have to recalculate the features on each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    }
   ],
   "source": [
    "featurenames = ft.load_features('../input/features.txt')\n",
    "print(len(featurenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Partition Data\n",
    "\n",
    "This function takes in a list of user ids (`SK_ID_CURR`) and creates a data partition for those users. It then returns the seven dataframes with only the users in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition(user_list, partition = None):\n",
    "    \"\"\"Creates a set of data with only the users in `user_list`. If `partition` is specified, then data is saved.\"\"\"\n",
    "    \n",
    "    # Subset based on user list\n",
    "    app_subset = app[app.index.isin(user_list)].copy().reset_index()\n",
    "    bureau_subset = bureau[bureau.index.isin(user_list)].copy().reset_index()\n",
    "    \n",
    "    # Drop SK_ID_CURR from bureau_balance, cash, credit, and installments\n",
    "    bureau_balance_subset = bureau_balance[bureau_balance.index.isin(user_list)].copy().reset_index(drop = True)\n",
    "    cash_subset = cash[cash.index.isin(user_list)].copy().reset_index(drop = True)\n",
    "    credit_subset = credit[credit.index.isin(user_list)].copy().reset_index(drop = True)\n",
    "    previous_subset = previous[previous.index.isin(user_list)].copy().reset_index()\n",
    "    installments_subset = installments[installments.index.isin(user_list)].copy().reset_index(drop = True)\n",
    "    \n",
    "    # Save files if partition is specified\n",
    "    if partition:\n",
    "        \n",
    "        directory = ',,./input/partitions/p%d' % (partition + 1)\n",
    "        os.makedirs(directory)\n",
    "\n",
    "        app_subset.to_csv('%s/app.csv' % directory, index = False)\n",
    "        bureau_subset.to_csv('%s/bureau.csv' % directory, index = False)\n",
    "        bureau_balance_subset.to_csv('%s/bureau_balance.csv' % directory, index = False)\n",
    "        cash_subset.to_csv('%s/cash.csv' % directory, index = False)\n",
    "        credit_subset.to_csv('%s/credit.csv' % directory, index = False)\n",
    "        previous_subset.to_csv('%s/previous.csv' % directory, index = False)\n",
    "        installments_subset.to_csv('%s/installments.csv' % directory, index = False)\n",
    "\n",
    "        print('Saved all files in partition {} to {}.'.format(partition + 1,directory))\n",
    "        \n",
    "    return {'app': app_subset, 'bureau': bureau_subset, 'bureau_balance': bureau_balance_subset, \n",
    "            'previous': previous_subset, 'installments': installments_subset,\n",
    "            'cash': cash_subset, 'credit': credit_subset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a list of list of ids. Each list of ids can be used to create a dataset with only those ids. Modify `n` to change the number of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "# Break into n chunks\n",
    "chunk_size = app.shape[0] // n\n",
    "\n",
    "# Construct an id list\n",
    "id_list = [list(app.iloc[i:i+chunk_size].index) for i in range(0, app.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ids in id_list:         356255.\n",
      "Total length of application data: 356255.\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Sanity check that we have not missed any ids\n",
    "print('Number of ids in id_list:         {}.'.format(len(list(chain(*id_list)))))\n",
    "print('Total length of application data: {}.'.format(len(app)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line tests the partitioning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['app', 'bureau', 'bureau_balance', 'previous', 'installments', 'cash', 'credit'])\n"
     ]
    }
   ],
   "source": [
    "data_dict = create_partition(id_list[0])\n",
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(data_dict['previous']['SK_ID_CURR'].isin(data_dict['app']['SK_ID_CURR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(data_dict['bureau']['SK_ID_CURR'].isin(data_dict['app']['SK_ID_CURR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_types = {'FLAG_CONT_MOBILE': vtypes.Boolean, 'FLAG_DOCUMENT_10': vtypes.Boolean, 'FLAG_DOCUMENT_11': vtypes.Boolean, 'FLAG_DOCUMENT_12': vtypes.Boolean, 'FLAG_DOCUMENT_13': vtypes.Boolean, 'FLAG_DOCUMENT_14': vtypes.Boolean, 'FLAG_DOCUMENT_15': vtypes.Boolean, 'FLAG_DOCUMENT_16': vtypes.Boolean, 'FLAG_DOCUMENT_17': vtypes.Boolean, 'FLAG_DOCUMENT_18': vtypes.Boolean, 'FLAG_DOCUMENT_19': vtypes.Boolean, 'FLAG_DOCUMENT_2': vtypes.Boolean, 'FLAG_DOCUMENT_20': vtypes.Boolean, 'FLAG_DOCUMENT_21': vtypes.Boolean, 'FLAG_DOCUMENT_3': vtypes.Boolean, 'FLAG_DOCUMENT_4': vtypes.Boolean, 'FLAG_DOCUMENT_5': vtypes.Boolean, 'FLAG_DOCUMENT_6': vtypes.Boolean, 'FLAG_DOCUMENT_7': vtypes.Boolean, 'FLAG_DOCUMENT_8': vtypes.Boolean, 'FLAG_DOCUMENT_9': vtypes.Boolean, 'FLAG_EMAIL': vtypes.Boolean, 'FLAG_EMP_PHONE': vtypes.Boolean, 'FLAG_MOBIL': vtypes.Boolean, 'FLAG_PHONE': vtypes.Boolean, 'FLAG_WORK_PHONE': vtypes.Boolean, 'LIVE_CITY_NOT_WORK_CITY': vtypes.Boolean, 'LIVE_REGION_NOT_WORK_REGION': vtypes.Boolean, 'REG_CITY_NOT_LIVE_CITY': vtypes.Boolean, 'REG_CITY_NOT_WORK_CITY': vtypes.Boolean, 'REG_REGION_NOT_LIVE_REGION': vtypes.Boolean, 'REG_REGION_NOT_WORK_REGION': vtypes.Boolean, 'REGION_RATING_CLIENT': vtypes.Ordinal, 'REGION_RATING_CLIENT_W_CITY': vtypes.Ordinal, 'HOUR_APPR_PROCESS_START': vtypes.Ordinal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_types = {'NFLAG_LAST_APPL_IN_DAY': vtypes.Boolean, \n",
    "             'NFLAG_INSURED_ON_APPROVAL': vtypes.Boolean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create EntitySet from Dataset\n",
    "\n",
    "Now that we can partition the data, we can use the smaller dataset to create an `EntitySet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_from_partition(data_dict, return_featurenames = False):\n",
    "    \"\"\"Create an EntitySet from a partition of data in a dictionary\"\"\"\n",
    "    \n",
    "    # Extract the dataframes\n",
    "    app = data_dict['app']\n",
    "    bureau = data_dict['bureau']\n",
    "    bureau_balance = data_dict['bureau_balance']\n",
    "    previous = data_dict['previous']\n",
    "    credit = data_dict['credit']\n",
    "    installments = data_dict['installments']\n",
    "    cash = data_dict['cash']\n",
    "    \n",
    "    # Add domain features to base dataframe\n",
    "    app['LOAN_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT'] \n",
    "    app['CREDIT_INCOME_RATIO'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "    app['EMPLOYED_BIRTH_RATIO'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "    app['EXT_SOURCE_SUM'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis = 1)\n",
    "    app['EXT_SOURCE_MEAN'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    app['AMT_REQ_SUM'] = app[[x for x in app.columns if 'AMT_REQ_' in x]].sum(axis = 1)\n",
    "    \n",
    "    \n",
    "    # Empty entityset\n",
    "    es = ft.EntitySet(id = 'clients')\n",
    "    \n",
    "    # Entities with a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR',\n",
    "                                  variable_types = app_types)\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV',\n",
    "                                  variable_types = previous_types)\n",
    "\n",
    "    # Entities that do not have a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                                  make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                                  make_index = True, index = 'cash_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                                  make_index = True, index = 'installments_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                                  make_index = True, index = 'credit_index')\n",
    "    \n",
    "    # Relationship between app_train and bureau\n",
    "    r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationship between bureau and bureau balance\n",
    "    r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "    # Relationship between current app and previous apps\n",
    "    r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationships between previous apps and cash, installments, and credit\n",
    "    r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "    r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "    r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
    "    \n",
    "    # Add in the defined relationships\n",
    "    es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                               r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "    \n",
    "    # Domain Features from bureau\n",
    "    es['bureau']['CREDIT_ACTIVE'].interesting_values = ['Active', 'Closed']\n",
    "\n",
    "\n",
    "    credit_overdue = ft.Feature(es['bureau']['CREDIT_DAY_OVERDUE']) > 0.0\n",
    "    credit_overdue = credit_overdue.rename('CREDIT_OVERDUE')\n",
    "\n",
    "    credit_loan_rate = ft.Feature(es['bureau']['AMT_ANNUITY']) / ft.Feature(es['bureau']['AMT_CREDIT_SUM'])\n",
    "    credit_loan_rate = credit_loan_rate.rename('PREVIOUS_OTHER_LOAN_RATE')\n",
    "\n",
    "\n",
    "    # Domain Features from bureau balance\n",
    "    balance_past_due = ft.Feature(es['bureau_balance']['STATUS']).isin(['1', '2', '3', '4', '5'])\n",
    "    balance_past_due = balance_past_due.rename('PREVIOUS_OTHER_MONTHLY_PAST_DUE')\n",
    "\n",
    "\n",
    "    # Domain Features from previous\n",
    "    es['previous']['NAME_CONTRACT_STATUS'].interesting_values = ['Approved', 'Refused']\n",
    "\n",
    "    previous_difference = ft.Feature(es['previous']['AMT_APPLICATION']) - ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_difference = previous_difference.rename('PREVIOUS_APPLICATION_RECEIVED_DIFFERENCE')\n",
    "\n",
    "    previous_loan_rate = ft.Feature(es['previous']['AMT_ANNUITY']) / ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_loan_rate = previous_loan_rate.rename('PREVIOUS_LOAN_RATE')\n",
    "\n",
    "\n",
    "    # Domain Features from credit\n",
    "    es['credit']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "\n",
    "    credit_card_past_due = ft.Feature(es['credit']['SK_DPD']) > 0.0\n",
    "    credit_card_past_due = credit_card_past_due.rename('CREDIT_CARD_PAST_DUE')\n",
    "\n",
    "\n",
    "    # Domain Features from cash\n",
    "    es['cash']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "\n",
    "    cash_past_due = ft.Feature(es['cash']['SK_DPD']) > 0.0\n",
    "    cash_past_due = cash_past_due.rename('CASH_PAST_DUE')\n",
    "\n",
    "    # Seed Features from installments\n",
    "    installments_late = ft.Feature(es['installments']['DAYS_ENTRY_PAYMENT']) > ft.Feature(es['installments']['DAYS_INSTALMENT'])\n",
    "    installments_late = installments_late.rename('INSTALLMENT_LATE')\n",
    "\n",
    "    installments_low_payment = ft.Feature(es['installments']['AMT_PAYMENT']) < ft.Feature(es['installments']['AMT_INSTALMENT'])\n",
    "    installments_low_payment = installments_low_payment.rename('INSTALLMENT_LOW')\n",
    "    \n",
    "    if return_featurenames:\n",
    "        # List of seed features\n",
    "        seed_features = [installments_low_payment, installments_late,\n",
    "                               cash_past_due, credit_card_past_due,\n",
    "                               previous_difference, previous_loan_rate,\n",
    "                               balance_past_due, credit_loan_rate, credit_overdue]\n",
    "\n",
    "\n",
    "        # Specify primitives\n",
    "        agg_primitives =  [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "        trans_primitives = ['percentile', 'and']\n",
    "        where_primitives = ['percent_true', 'mean', 'sum']\n",
    "\n",
    "        # Features only\n",
    "        feature_names = ft.dfs(entityset=es, target_entity='app',\n",
    "                               agg_primitives = agg_primitives,\n",
    "                               trans_primitives = trans_primitives,\n",
    "                               seed_features = seed_features,\n",
    "                               where_primitives = where_primitives,\n",
    "                               n_jobs = -1, verbose = 1, features_only = True,\n",
    "                               max_depth = 2)\n",
    "        \n",
    "        return feature_names\n",
    "    \n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function to make sure it can make an `EntitySet` from a data partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app [Rows: 356, Columns: 128]\n",
       "    bureau [Rows: 1644, Columns: 17]\n",
       "    previous [Rows: 1685, Columns: 37]\n",
       "    bureau_balance [Rows: 15815, Columns: 4]\n",
       "    cash [Rows: 10314, Columns: 8]\n",
       "    installments [Rows: 13904, Columns: 8]\n",
       "    credit [Rows: 4207, Columns: 23]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es1 = entityset_from_partition(data_dict)\n",
    "es1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works! The last step is to create a featurematrix from the `EntitySet` and the `features`. \n",
    "\n",
    "## Function to Create Featurematrix from EntitySet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix_from_entityset(es, feature_names):\n",
    "    \n",
    "    \"\"\"Run deep feature synthesis from an entityset and feature names\"\"\"\n",
    "\n",
    "    feature_matrix = ft.calculate_feature_matrix(feature_names, \n",
    "                                                 entityset=es, \n",
    "                                                 n_jobs = 1, \n",
    "                                                 verbose = 0,\n",
    "                                                 chunk_size = 100)\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 2800)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm1 = feature_matrix_from_entityset(es1, featurenames)\n",
    "fm1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the parts needed to create our feature matrixes. The last step is to get Dask to run this in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "We will use the Dask utility `bag.from_sequence` to parallelize the operation. We create a `bag` out of our list of lists of ids (the first 10 for now) and then map each function required to go from each list of ids to a feature matrix. The final step is to `concat` the individual feature matrices into a single feature matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar, Profiler, ResourceProfiler, CacheProfiler\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fms = []\n",
    "\n",
    "for ids in id_list:\n",
    "    ds = delayed(create_partition)(ids)\n",
    "    es = delayed(entityset_from_partition)(ds)\n",
    "    fm = delayed(feature_matrix_from_entityset)(es, feature_names = featurenames)\n",
    "    fms.append(fm)\n",
    "    \n",
    "X = delayed(pd.concat)(fms, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####                                    ] | 10% Completed |  2hr 29min  3.2s"
     ]
    }
   ],
   "source": [
    "with ProgressBar(), Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
    "    feature_matrix = X.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.to_csv('../input/feature_matrix.csv', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "prof.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_from_filepath(path):\n",
    "    app = pd.read_csv('%s/app.csv' % path)\n",
    "    bureau = pd.read_csv('%s/bureau.csv' % path)\n",
    "    \n",
    "    bureau_balance = pd.read_csv('%s/bureau_balance.csv' % path)\n",
    "    \n",
    "    previous = pd.read_csv('%s/previous.csv' % path)\n",
    "    \n",
    "    credit = pd.read_csv('%s/credit.csv' % path)\n",
    "    installments = pd.read_csv('%s/installments.csv' % path)\n",
    "    cash = pd.read_csv('%s/cash.csv' % path)\n",
    "    \n",
    "    # All ids should be integers\n",
    "    for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "        for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "            if index in list(dataset.columns):\n",
    "                # Convert to integers after filling in missing values (not sure why values are missing)\n",
    "                dataset[index] = dataset[index].fillna(0).astype(np.int64)\n",
    "    \n",
    "    app_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in app:\n",
    "        if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "            app_types[col] = vtypes.Boolean\n",
    "\n",
    "    # Remove the `TARGET`\n",
    "    if 'TARGET' in app_types:\n",
    "        del app_types['TARGET']\n",
    "    \n",
    "    previous_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in previous:\n",
    "        if (previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "            previous_types[col] = vtypes.Boolean\n",
    "    \n",
    "    es = ft.EntitySet(id = 'clients')\n",
    "    \n",
    "    app['LOAN_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT'] \n",
    "    app['CREDIT_INCOME_RATIO'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "    app['EMPLOYED_BIRTH_RATIO'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "    app['EXT_SOURCE_SUM'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis = 1)\n",
    "    app['EXT_SOURCE_MEAN'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    app['AMT_REQ_SUM'] = app[[x for x in app.columns if 'AMT_REQ_' in x]].sum(axis = 1)\n",
    "    \n",
    "    # Entities with a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR',\n",
    "                                  variable_types = app_types)\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV',\n",
    "                                  variable_types = previous_types)\n",
    "\n",
    "    # Entities that do not have a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                                  make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                                  make_index = True, index = 'cash_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                                  make_index = True, index = 'installments_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                                  make_index = True, index = 'credit_index')\n",
    "    \n",
    "    # Relationship between app_train and bureau\n",
    "    r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationship between bureau and bureau balance\n",
    "    r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "    # Relationship between current app and previous apps\n",
    "    r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationships between previous apps and cash, installments, and credit\n",
    "    r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "    r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "    r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
    "    \n",
    "    # Add in the defined relationships\n",
    "    es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                               r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "    \n",
    "    # Bureau interesting values\n",
    "    es['bureau']['CREDIT_ACTIVE'].interesting_values = ['Active', 'Closed']\n",
    "    \n",
    "    # Bureau seed features\n",
    "    credit_overdue = ft.Feature(es['bureau']['CREDIT_DAY_OVERDUE']) > 0.0\n",
    "    credit_overdue = credit_overdue.rename('CREDIT_OVERDUE')\n",
    "\n",
    "    credit_loan_rate = ft.Feature(es['bureau']['AMT_ANNUITY']) / ft.Feature(es['bureau']['AMT_CREDIT_SUM'])\n",
    "    credit_loan_rate = credit_loan_rate.rename('PREVIOUS_OTHER_LOAN_RATE')\n",
    "    \n",
    "    # Bureau balance seed features\n",
    "    balance_past_due = ft.Feature(es['bureau_balance']['STATUS']).isin(['1', '2', '3', '4', '5'])\n",
    "    balance_past_due = balance_past_due.rename('PREVIOUS_OTHER_MONTHLY_PAST_DUE')\n",
    "    \n",
    "    # Previous interesting values\n",
    "    es['previous']['NAME_CONTRACT_STATUS'].interesting_values = ['Approved', 'Refused']\n",
    "    \n",
    "    # Previous seed features\n",
    "    previous_difference = ft.Feature(es['previous']['AMT_APPLICATION']) - ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_difference = previous_difference.rename('PREVIOUS_APPLICATION_RECEIVED_DIFFERENCE')\n",
    "\n",
    "    previous_loan_rate = ft.Feature(es['previous']['AMT_ANNUITY']) / ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_loan_rate = previous_loan_rate.rename('PREVIOUS_LOAN_RATE')\n",
    "    \n",
    "    # Credit interesting values\n",
    "    es['credit']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Credit seed features\n",
    "    credit_card_past_due = ft.Feature(es['credit']['SK_DPD']) > 0.0\n",
    "    credit_card_past_due = credit_card_past_due.rename('CREDIT_CARD_PAST_DUE')\n",
    "    \n",
    "    # Cash interesting values\n",
    "    es['cash']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Cash seed features\n",
    "    cash_past_due = ft.Feature(es['cash']['SK_DPD']) > 0.0\n",
    "    cash_past_due = cash_past_due.rename('CASH_PAST_DUE')\n",
    "    \n",
    "    # Installments seed features\n",
    "    installments_late = ft.Feature(es['installments']['DAYS_ENTRY_PAYMENT']) > ft.Feature(es['installments']['DAYS_INSTALMENT'])\n",
    "    installments_late = installments_late.rename('INSTALLMENT_LATE')\n",
    "\n",
    "    installments_low_payment = ft.Feature(es['installments']['AMT_PAYMENT']) < ft.Feature(es['installments']['AMT_INSTALMENT']) \n",
    "    installments_low_payment = installments_low_payment.rename('INSTALLMENT_LOW')\n",
    "    \n",
    "    # List of seed features\n",
    "    seed_features = [installments_low_payment, installments_late,\n",
    "                       cash_past_due, credit_card_past_due, \n",
    "                       previous_difference, previous_loan_rate,\n",
    "                       balance_past_due, credit_loan_rate, credit_overdue]\n",
    "    \n",
    "    # print total size of entityset in gb\n",
    "    # print('Total size of entityset: {:.5f} gb.'.format(sys.getsizeof(es) / 1e9))\n",
    "    \n",
    "    return es#, seed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_from_filepath(path):\n",
    "    app = pd.read_csv('%s/app.csv' % path)\n",
    "    bureau = pd.read_csv('%s/bureau.csv' % path)\n",
    "    \n",
    "    bureau_balance = pd.read_csv('%s/bureau_balance.csv' % path)\n",
    "    \n",
    "    previous = pd.read_csv('%s/previous.csv' % path)\n",
    "    \n",
    "    credit = pd.read_csv('%s/credit.csv' % path)\n",
    "    installments = pd.read_csv('%s/installments.csv' % path)\n",
    "    cash = pd.read_csv('%s/cash.csv' % path)\n",
    "    \n",
    "    # All ids should be integers\n",
    "    for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "        for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "            if index in list(dataset.columns):\n",
    "                # Convert to integers after filling in missing values (not sure why values are missing)\n",
    "                dataset[index] = dataset[index].fillna(0).astype(np.int64)\n",
    "    \n",
    "    app_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in app:\n",
    "        if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "            app_types[col] = vtypes.Boolean\n",
    "\n",
    "    # Remove the `TARGET`\n",
    "    if 'TARGET' in app_types:\n",
    "        del app_types['TARGET']\n",
    "    \n",
    "    previous_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in previous:\n",
    "        if (previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "            previous_types[col] = vtypes.Boolean\n",
    "    \n",
    "    es = ft.EntitySet(id = 'clients')\n",
    "    \n",
    "    app['LOAN_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT'] \n",
    "    app['CREDIT_INCOME_RATIO'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "    app['EMPLOYED_BIRTH_RATIO'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "    app['EXT_SOURCE_SUM'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis = 1)\n",
    "    app['EXT_SOURCE_MEAN'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    app['AMT_REQ_SUM'] = app[[x for x in app.columns if 'AMT_REQ_' in x]].sum(axis = 1)\n",
    "    \n",
    "    # Entities with a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR',\n",
    "                                  variable_types = app_types)\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV',\n",
    "                                  variable_types = previous_types)\n",
    "\n",
    "    # Entities that do not have a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                                  make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                                  make_index = True, index = 'cash_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                                  make_index = True, index = 'installments_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                                  make_index = True, index = 'credit_index')\n",
    "    \n",
    "    # Relationship between app_train and bureau\n",
    "    r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationship between bureau and bureau balance\n",
    "    r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "    # Relationship between current app and previous apps\n",
    "    r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationships between previous apps and cash, installments, and credit\n",
    "    r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "    r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "    r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
    "    \n",
    "    # Add in the defined relationships\n",
    "    es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                               r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "    \n",
    "    # Bureau interesting values\n",
    "    es['bureau']['CREDIT_ACTIVE'].interesting_values = ['Active', 'Closed']\n",
    "    \n",
    "    # Bureau seed features\n",
    "    credit_overdue = ft.Feature(es['bureau']['CREDIT_DAY_OVERDUE']) > 0.0\n",
    "    credit_overdue = credit_overdue.rename('CREDIT_OVERDUE')\n",
    "\n",
    "    credit_loan_rate = ft.Feature(es['bureau']['AMT_ANNUITY']) / ft.Feature(es['bureau']['AMT_CREDIT_SUM'])\n",
    "    credit_loan_rate = credit_loan_rate.rename('PREVIOUS_OTHER_LOAN_RATE')\n",
    "    \n",
    "    # Bureau balance seed features\n",
    "    balance_past_due = ft.Feature(es['bureau_balance']['STATUS']).isin(['1', '2', '3', '4', '5'])\n",
    "    balance_past_due = balance_past_due.rename('PREVIOUS_OTHER_MONTHLY_PAST_DUE')\n",
    "    \n",
    "    # Previous interesting values\n",
    "    es['previous']['NAME_CONTRACT_STATUS'].interesting_values = ['Approved', 'Refused']\n",
    "    \n",
    "    # Previous seed features\n",
    "    previous_difference = ft.Feature(es['previous']['AMT_APPLICATION']) - ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_difference = previous_difference.rename('PREVIOUS_APPLICATION_RECEIVED_DIFFERENCE')\n",
    "\n",
    "    previous_loan_rate = ft.Feature(es['previous']['AMT_ANNUITY']) / ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_loan_rate = previous_loan_rate.rename('PREVIOUS_LOAN_RATE')\n",
    "    \n",
    "    # Credit interesting values\n",
    "    es['credit']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Credit seed features\n",
    "    credit_card_past_due = ft.Feature(es['credit']['SK_DPD']) > 0.0\n",
    "    credit_card_past_due = credit_card_past_due.rename('CREDIT_CARD_PAST_DUE')\n",
    "    \n",
    "    # Cash interesting values\n",
    "    es['cash']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Cash seed features\n",
    "    cash_past_due = ft.Feature(es['cash']['SK_DPD']) > 0.0\n",
    "    cash_past_due = cash_past_due.rename('CASH_PAST_DUE')\n",
    "    \n",
    "    # Installments seed features\n",
    "    installments_late = ft.Feature(es['installments']['DAYS_ENTRY_PAYMENT']) > ft.Feature(es['installments']['DAYS_INSTALMENT'])\n",
    "    installments_late = installments_late.rename('INSTALLMENT_LATE')\n",
    "\n",
    "    installments_low_payment = ft.Feature(es['installments']['AMT_PAYMENT']) < ft.Feature(es['installments']['AMT_INSTALMENT']) \n",
    "    installments_low_payment = installments_low_payment.rename('INSTALLMENT_LOW')\n",
    "    \n",
    "    # List of seed features\n",
    "    seed_features = [installments_low_payment, installments_late,\n",
    "                       cash_past_due, credit_card_past_due, \n",
    "                       previous_difference, previous_loan_rate,\n",
    "                       balance_past_due, credit_loan_rate, credit_overdue]\n",
    "    \n",
    "    # print total size of entityset in gb\n",
    "    # print('Total size of entityset: {:.5f} gb.'.format(sys.getsizeof(es) / 1e9))\n",
    "    \n",
    "    return es#, seed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_from_entityset(es, seed_features, agg_primitives = None, \n",
    "                       trans_primitives = None, where_primitives = None):\n",
    "    \n",
    "    \"\"\"Run deep feature synthesis from an entityset. Specific to the Home Credit Competition\"\"\"\n",
    "    \n",
    "    if not agg_primitives:\n",
    "        agg_primitives =  [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "        \n",
    "    if not trans_primitives:\n",
    "        trans_primitives = ['percentile', 'and']\n",
    "    \n",
    "    if not where_primitives:\n",
    "        where_primitives = ['percent_true', 'mean', 'sum']\n",
    "    \n",
    "    # Deep feature synthesis with domain knowledge (only features)\n",
    "    feature_names = ft.dfs(entityset=es, target_entity='app',\n",
    "                           agg_primitives = agg_primitives,\n",
    "                           trans_primitives = trans_primitives,\n",
    "                           seed_features = seed_features,\n",
    "                           where_primitives = where_primitives,\n",
    "                           n_jobs = 1, verbose = 1, features_only = True,\n",
    "                           max_depth = 2)\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix_from_entityset(es, feature_names):\n",
    "    \n",
    "    \"\"\"Run deep feature synthesis from an entityset. Specific to the Home Credit Competition\"\"\"\n",
    "\n",
    "    \n",
    "    # Deep feature synthesis with domain knowledge (only features)\n",
    "    feature_matrix = ft.calculate_feature_matrix(feature_names, \n",
    "                                                 entityset=es, \n",
    "                                                 n_jobs = 1, \n",
    "                                                 verbose = 1)\n",
    "    \n",
    "    return feature_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
