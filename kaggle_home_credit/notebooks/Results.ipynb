{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: Manual vs Automated Feature Engineering\n",
    "\n",
    "In this notebook, we will compare the manual and automated feature engineering approaches for the Kaggle Home Credit Default Risk competition. The comparison will be done in terms of time (how long it took to complete) and the performance (the score in cross validation and when submitted to the Kaggle leaderboard.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>iteration</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.780678</td>\n",
       "      <td>{'verbose': 1, 'is_unbalance': True, 'boosting...</td>\n",
       "      <td>125</td>\n",
       "      <td>384.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.780417</td>\n",
       "      <td>{'verbose': 1, 'is_unbalance': True, 'boosting...</td>\n",
       "      <td>109</td>\n",
       "      <td>370.445021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.780216</td>\n",
       "      <td>{'verbose': 1, 'is_unbalance': True, 'boosting...</td>\n",
       "      <td>9</td>\n",
       "      <td>137.456086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.780154</td>\n",
       "      <td>{'verbose': 1, 'is_unbalance': True, 'boosting...</td>\n",
       "      <td>41</td>\n",
       "      <td>134.778583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.780134</td>\n",
       "      <td>{'verbose': 1, 'is_unbalance': True, 'boosting...</td>\n",
       "      <td>97</td>\n",
       "      <td>169.808482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score                                    hyperparameters  iteration  \\\n",
       "125  0.780678  {'verbose': 1, 'is_unbalance': True, 'boosting...        125   \n",
       "109  0.780417  {'verbose': 1, 'is_unbalance': True, 'boosting...        109   \n",
       "9    0.780216  {'verbose': 1, 'is_unbalance': True, 'boosting...          9   \n",
       "41   0.780154  {'verbose': 1, 'is_unbalance': True, 'boosting...         41   \n",
       "97   0.780134  {'verbose': 1, 'is_unbalance': True, 'boosting...         97   \n",
       "\n",
       "           time  \n",
       "125  384.011306  \n",
       "109  370.445021  \n",
       "9    137.456086  \n",
       "41   134.778583  \n",
       "97   169.808482  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual = pd.read_csv('../input/results/random_search_domain_manual_features_fast.csv').sort_values('score', ascending = False)\n",
    "manual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
