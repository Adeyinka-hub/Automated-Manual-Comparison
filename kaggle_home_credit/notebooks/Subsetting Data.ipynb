{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting Data\n",
    "\n",
    "In this notebook, we subset the full feature matrices to the features identified in the `Sampling` notebook. The `_sample.csv` files are the sampled version (10% of the observations) with the feature selection applied. The `fm` dataframes are the full data. The full data after being subsetted is then saved as `_selected.csv`.\n",
    "\n",
    "The random search is run on the `_sample.csv` files, but the `_selected.csv` files will be used to train and test the final model. These files have all the observations, but only the columns that remained after feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 243)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = pd.read_csv('../input/application_train.csv'), pd.read_csv('../input/application_test.csv')\n",
    "test['TARGET'] = np.nan\n",
    "train, test = pd.get_dummies(train).align(pd.get_dummies(test), axis = 1, join = 'inner')\n",
    "\n",
    "sample = pd.read_csv('../input/features_default_sample.csv')\n",
    "fm = train.append(test, ignore_index = True)\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 204)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = fm[[x for x in sample.columns if x in fm.columns]]\n",
    "fm.to_csv('../input/features_default_selected.csv')\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 273)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('../input/features_manual_sample.csv')\n",
    "fm = pd.read_csv('../input/features_manual.csv')\n",
    "\n",
    "# One-hot encoding\n",
    "fm = pd.get_dummies(fm)\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset to the columns in the sample\n",
    "fm = fm[sample.columns]\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "fm.to_csv('../input/features_manual_selected.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuretools Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 1821)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(356255, 2111)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in sample and full data\n",
    "sample = pd.read_csv('../input/feature_matrix_sample.csv')\n",
    "fm = pd.read_csv('../input/feature_matrix.csv')\n",
    "\n",
    "print(fm.shape)\n",
    "\n",
    "# One hot encoding\n",
    "cat = pd.get_dummies(fm.select_dtypes('object'))\n",
    "\n",
    "# Convert the column types\n",
    "for col in fm:\n",
    "    if fm[col].dtype == 'bool':\n",
    "        fm[col] = fm[col].astype(np.uint8)\n",
    "        \n",
    "# Add the one-hot encoded columns\n",
    "fm = fm.select_dtypes(['number'])\n",
    "fm = pd.concat([fm, cat], axis = 1)\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30751, 1042)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('../input/feature_matrix_sample.csv')\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1042)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset to the columns in the sample\n",
    "fm = fm[[x for x in sample.columns if x in fm]]\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "fm.to_csv('../input/feature_matrix_select.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Automated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1447)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('../input/features_semi_sample.csv')\n",
    "fm = pd.read_csv('../input/features_semi.csv')\n",
    "\n",
    "# One hot encoding\n",
    "fm = pd.get_dummies(fm)\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 880)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset to the columns in sample\n",
    "fm = fm[sample.columns]\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.to_csv('../input/features_semi_selected.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The resulting data can now be used for modeling. The columns have been reduced through feature selection but all of the observations remain. The final datasets will be tested both with the default gradient boosting machine hyperparameters and with the optimal hyperparameters found from random search. The next notebook is Results which implements these datasets with the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
