{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will develop a function to perform dfs from an existing entityset. This reads in the entityset, creates the seed features and the interesting values, and then runs deep feature synthesis on the entityset. This code is specific to the Home Credit competition (for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_from_filepath(path):\n",
    "    app = pd.read_csv('%s/app.csv' % path)\n",
    "    bureau = pd.read_csv('%s/bureau.csv' % path)\n",
    "    \n",
    "    bureau_balance = pd.read_csv('%s/bureau_balance.csv' % path)\n",
    "    \n",
    "    previous = pd.read_csv('%s/previous.csv' % path)\n",
    "    \n",
    "    credit = pd.read_csv('%s/credit.csv' % path)\n",
    "    installments = pd.read_csv('%s/installments.csv' % path)\n",
    "    cash = pd.read_csv('%s/cash.csv' % path)\n",
    "    \n",
    "    # All ids should be integers\n",
    "    for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "        for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "            if index in list(dataset.columns):\n",
    "                # Convert to integers after filling in missing values (not sure why values are missing)\n",
    "                dataset[index] = dataset[index].fillna(0).astype(np.int64)\n",
    "    \n",
    "    app_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in app:\n",
    "        if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "            app_types[col] = vtypes.Boolean\n",
    "\n",
    "    # Remove the `TARGET`\n",
    "    if 'TARGET' in app_types:\n",
    "        del app_types['TARGET']\n",
    "    \n",
    "    previous_types = {}\n",
    "\n",
    "    # Handle the Boolean variables:\n",
    "    for col in previous:\n",
    "        if (previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "            previous_types[col] = vtypes.Boolean\n",
    "    \n",
    "    es = ft.EntitySet(id = 'clients')\n",
    "    \n",
    "    app['LOAN_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT'] \n",
    "    app['CREDIT_INCOME_RATIO'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "    app['EMPLOYED_BIRTH_RATIO'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "    app['EXT_SOURCE_SUM'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis = 1)\n",
    "    app['EXT_SOURCE_MEAN'] = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    app['AMT_REQ_SUM'] = app[[x for x in app.columns if 'AMT_REQ_' in x]].sum(axis = 1)\n",
    "    \n",
    "    # Entities with a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR',\n",
    "                                  variable_types = app_types)\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV',\n",
    "                                  variable_types = previous_types)\n",
    "\n",
    "    # Entities that do not have a unique index\n",
    "    es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                                  make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                                  make_index = True, index = 'cash_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                                  make_index = True, index = 'installments_index')\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                                  make_index = True, index = 'credit_index')\n",
    "    \n",
    "    # Relationship between app_train and bureau\n",
    "    r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationship between bureau and bureau balance\n",
    "    r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "    # Relationship between current app and previous apps\n",
    "    r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "    # Relationships between previous apps and cash, installments, and credit\n",
    "    r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "    r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "    r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
    "    \n",
    "    # Add in the defined relationships\n",
    "    es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                               r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "    \n",
    "    # Bureau interesting values\n",
    "    es['bureau']['CREDIT_ACTIVE'].interesting_values = ['Active', 'Closed']\n",
    "    \n",
    "    # Bureau seed features\n",
    "    credit_overdue = ft.Feature(es['bureau']['CREDIT_DAY_OVERDUE']) > 0.0\n",
    "    credit_overdue = credit_overdue.rename('CREDIT_OVERDUE')\n",
    "\n",
    "    credit_loan_rate = ft.Feature(es['bureau']['AMT_ANNUITY']) / ft.Feature(es['bureau']['AMT_CREDIT_SUM'])\n",
    "    credit_loan_rate = credit_loan_rate.rename('PREVIOUS_OTHER_LOAN_RATE')\n",
    "    \n",
    "    # Bureau balance seed features\n",
    "    balance_past_due = ft.Feature(es['bureau_balance']['STATUS']).isin(['1', '2', '3', '4', '5'])\n",
    "    balance_past_due = balance_past_due.rename('PREVIOUS_OTHER_MONTHLY_PAST_DUE')\n",
    "    \n",
    "    # Previous interesting values\n",
    "    es['previous']['NAME_CONTRACT_STATUS'].interesting_values = ['Approved', 'Refused']\n",
    "    \n",
    "    # Previous seed features\n",
    "    previous_difference = ft.Feature(es['previous']['AMT_APPLICATION']) - ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_difference = previous_difference.rename('PREVIOUS_APPLICATION_RECEIVED_DIFFERENCE')\n",
    "\n",
    "    previous_loan_rate = ft.Feature(es['previous']['AMT_ANNUITY']) / ft.Feature(es['previous']['AMT_CREDIT'])\n",
    "    previous_loan_rate = previous_loan_rate.rename('PREVIOUS_LOAN_RATE')\n",
    "    \n",
    "    # Credit interesting values\n",
    "    es['credit']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Credit seed features\n",
    "    credit_card_past_due = ft.Feature(es['credit']['SK_DPD']) > 0.0\n",
    "    credit_card_past_due = credit_card_past_due.rename('CREDIT_CARD_PAST_DUE')\n",
    "    \n",
    "    # Cash interesting values\n",
    "    es['cash']['NAME_CONTRACT_STATUS'].interesting_values = ['Active', 'Completed']\n",
    "    \n",
    "    # Cash seed features\n",
    "    cash_past_due = ft.Feature(es['cash']['SK_DPD']) > 0.0\n",
    "    cash_past_due = cash_past_due.rename('CASH_PAST_DUE')\n",
    "    \n",
    "    # Installments seed features\n",
    "    installments_late = ft.Feature(es['installments']['DAYS_ENTRY_PAYMENT']) > ft.Feature(es['installments']['DAYS_INSTALMENT'])\n",
    "    installments_late = installments_late.rename('INSTALLMENT_LATE')\n",
    "\n",
    "    installments_low_payment = ft.Feature(es['installments']['AMT_PAYMENT']) < ft.Feature(es['installments']['AMT_INSTALMENT']) \n",
    "    installments_low_payment = installments_low_payment.rename('INSTALLMENT_LOW')\n",
    "    \n",
    "    # List of seed features\n",
    "    seed_features = [installments_low_payment, installments_late,\n",
    "                       cash_past_due, credit_card_past_due, \n",
    "                       previous_difference, previous_loan_rate,\n",
    "                       balance_past_due, credit_loan_rate, credit_overdue]\n",
    "    \n",
    "    # print total size of entityset in gb\n",
    "    # print('Total size of entityset: {:.5f} gb.'.format(sys.getsizeof(es) / 1e9))\n",
    "    \n",
    "    return es#, seed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_from_entityset(es, seed_features, agg_primitives = None, \n",
    "                       trans_primitives = None, where_primitives = None):\n",
    "    \n",
    "    \"\"\"Run deep feature synthesis from an entityset. Specific to the Home Credit Competition\"\"\"\n",
    "    \n",
    "    if not agg_primitives:\n",
    "        agg_primitives =  [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "        \n",
    "    if not trans_primitives:\n",
    "        trans_primitives = ['percentile', 'and']\n",
    "    \n",
    "    if not where_primitives:\n",
    "        where_primitives = ['percent_true', 'mean', 'sum']\n",
    "    \n",
    "    # Deep feature synthesis with domain knowledge (only features)\n",
    "    feature_names = ft.dfs(entityset=es, target_entity='app',\n",
    "                           agg_primitives = agg_primitives,\n",
    "                           trans_primitives = trans_primitives,\n",
    "                           seed_features = seed_features,\n",
    "                           where_primitives = where_primitives,\n",
    "                           n_jobs = 1, verbose = 1, features_only = True,\n",
    "                           max_depth = 2)\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix_from_entityset(es, feature_names):\n",
    "    \n",
    "    \"\"\"Run deep feature synthesis from an entityset. Specific to the Home Credit Competition\"\"\"\n",
    "\n",
    "    \n",
    "    # Deep feature synthesis with domain knowledge (only features)\n",
    "    feature_matrix = ft.calculate_feature_matrix(feature_names, \n",
    "                                                 entityset=es, \n",
    "                                                 n_jobs = 1, \n",
    "                                                 verbose = 1)\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ft.load_features('../../data/kaggle_home_credit/features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client()  # use dask.distributed by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "base = \"../../data/kaggle_home_credit/partitions/\"\n",
    "paths = os.listdir(base)\n",
    "\n",
    "fms = []\n",
    "for p in paths:\n",
    "    es = delayed(entityset_from_filepath)(base+p)\n",
    "    fm = delayed(feature_matrix_from_entityset)(es, feature_names)\n",
    "    fms.append(fm)\n",
    "\n",
    "\n",
    "# dask.config.set(scheduler='processes')\n",
    "out = delayed(pd.concat)(fms, axis=0)\n",
    "\n",
    "with ProgressBar():\n",
    "    x = out.compute()\n",
    "    \n",
    "timer() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('feature_matrix.csv', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_names, '../../data/kaggle_home_credit/features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
