{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Feature Engineering\n",
    "\n",
    "In this notebook, we will implement an automated feature engineering solution in Featuretools for a set of online retail purchases. The dataset (available from the [UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/online+retail#)), a series of time-stamped purchases, does not come with any labels, so we'll have to make our own prediction problem. After defining the problem, we can use automated feature engineering to build a set of features that we then feed to a machine learning model for training. \n",
    "\n",
    "This set of data is great practice both for defining our own prediction problem, and for using some of the time-based capabilities of Featuretools such as cutoff times. Whenever we have time-series data, we need to be extra careful to not \"leak labels\" or use information from the future to predict a past event. Usually, when we're doing manual feature engineering, this can be quite an issue and often, a system will work well in development but utterly fail when deployed because it was trained on illegitimate data. Fortunately, Featuretools will take care of the time issue for us, creating a rich set of features that follow any time limitations. \n",
    "\n",
    "## Roadmap \n",
    "\n",
    "Following is an outline for this notebook:\n",
    "\n",
    "1. Read in data, inspect, and clean\n",
    "2. Develop a prediction problem\n",
    "    * Create a dataframe of labels - what we want to predict, and cutoff times - the point that all data must come before for predicting a label\n",
    "3. Create an entityset and add entities\n",
    "    * Normalize the original table to develop new tables \n",
    "    * These new tables can be used for making features\n",
    "3. Run deep feature sythesis on the entityset to make features\n",
    "    * Use the cutoff times to make features using valid data for each label\n",
    "4. Use the features to train a machine learning model\n",
    "    * Measure performance of the model relative to an informed baseline\n",
    "5. Tune deep feature synthesis \n",
    "    * Specify custom primitives\n",
    "    * Adjust maximum depth of features\n",
    "6. Use random search for hyperparameter tuning the model\n",
    "\n",
    "This problem is a great display of both the time and feature-creation capabilities of Featuretools. Doing this problem by hand and ensuring we use only valid data for each label is a daunting task! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Raw Data\n",
    "\n",
    "The raw data is a collection of purchases from an online retailer collected in 2011. Each row in the original data represents one product that was purchased with multiple purchases forming an order. There are a few issues with the data that will need to be addressed (as with most real-world datasets)!\n",
    "\n",
    "This code loads in the data from an s3 bucket, converts the price in Pounds to dollars (based on the exchange rate on May 31, 2011), and creates a column representing the total of the purchase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_s3 = \"s3://featurelabs-static/online-retail-logs.csv\"\n",
    "data = pd.read_csv(csv_s3, parse_dates=[\"order_date\"])\n",
    "\n",
    "# Convert to dollars\n",
    "data['price'] = data['price'] * 1.65\n",
    "data['total'] = data['price'] * data['quantity']\n",
    "\n",
    "# Restrict data to 2011\n",
    "data = data[data['order_date'].dt.year == 2011]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "There are a few issues we need to address with the data. First, we'll drop the duplicated rows, then we'll drop any rows that contain a `nan`. Finally, we can add a `Boolean` column indicating whether or not an order is a cancellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# drop rows with null customer id\n",
    "data = data.dropna(axis=0)\n",
    "\n",
    "data['cancelled'] = data['order_id'].str.startswith('C')\n",
    "data['cancelled'].value_counts().plot.bar(figsize = (6, 5));\n",
    "plt.title('Cancelled Purchases Breakdown');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the cancelled orders have negative quantities which mean that they cancel out with the corresponding purchase. We'll leave in the cancelled purchases, because if our goal (defined later in the prediction problem) is to predict the total amount purchased by a customer, we'll need to take into account their cancelled orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most total purchase prices are less than \\$50. We can plot the purchase total by country (limited to only positive amounts and less than \\$1000) to see if there are differences between countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 6))\n",
    "sns.boxplot(x = 'country', y = 'total', data = data[(data['total'] > 0) & (data['total'] < 1000)]);\n",
    "plt.title(\"Total Purchase Amount by Country\");\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 6))\n",
    "sns.boxplot(x = 'country', y = 'quantity', data = data[(data['total'] > 0) & (data['total'] < 1000)]);\n",
    "plt.title(\"Purchased Quantity by Country\");\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the purchase total and the quantity are heavily skewed. This occurs often in real-world data and means this might be difficult as a regression problem (predict the actual spending amount). We might want to frame the problem as classification because the large purchase totals could throw off a machine learning algorithm. Our other option would be to remove the outliers, but given that these are probably legitimate, that does not seem like a responsible choice!\n",
    "\n",
    "To see the extent of how skewed the data is, we can use an [Empirical Cumulative Distribution Function (ECDF) plot](https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/ecdfplot.htm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, len(x) + 1) / len(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "# Total\n",
    "plt.subplot(121)\n",
    "x, y = ecdf(data.loc[data['total'] > 0, 'total'])\n",
    "plt.plot(x, y, marker = '.')\n",
    "plt.xlabel('Total'); plt.ylabel('Percentile'); plt.title('ECDF of Purchase Total');\n",
    "\n",
    "# Quantity\n",
    "plt.subplot(122)\n",
    "x, y = ecdf(data.loc[data['total'] > 0, 'quantity'])\n",
    "plt.plot(x, y, marker = '.')\n",
    "plt.xlabel('Quantity'); plt.ylabel('Percentile'); plt.title('ECDF of Purchase Quantity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Problem\n",
    "\n",
    "The goal of machine learning is to predict some quantity (regression) or a label (classification). Our data exploration showed that regression might not be the best approach because of the outliers, so we'll choose classification. We'll frame the problem as predicting whether or not a customer will spend more than \\$500 in the next month. This could be useful to a business because it will let them market more effectively to those customers who are likely to spend more. Moreover, an online retailer could advertise differently to customers based on their predicted class of spending. \n",
    "\n",
    "Instead of picking just a single month for predictions, we can use each customer as a label multiple times. In other words, we not only predict whether a given customer will spend more than \\$500 in May, but we also ask the same question in June, July, and so on. The thing to note is that for each month, we _can't use data from the future_ to predict the class of spending. Each month we can use information from _any previous month_ which means that our predictions should get more accurate as we advance further in time through the data since we'll be able to use more information. Each label for a customer therefore has a different set of features because there is more or less data available to us depending on the month. Doing this by hand is very tedious and error-prone, but we'll see how Featuretools is able to handle the times associated with each label to only generate legitimate features. \n",
    "\n",
    "## Making Labels\n",
    "\n",
    "The function below takes in a start date and an end date (which we can set to 30 days apart) and generates a dataframe of the labels, which depends on how much the customer spent in the period. For customers who appear in the data prior to the start date but then do have a purchase in between the start and end date, we want to set their total to 0. If we simply did not include them in the labels, then that would be cheating since we have no way of knowing ahead of time that they will not spend anything in the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retail_cutoffs_total(start_date, end_date, threshold = 500):\n",
    "    \n",
    "    # Find customers who exist before start date\n",
    "    customer_pool = data[data['order_date'] < start_date]['customer_id'].unique()\n",
    "    tmp = pd.DataFrame({'customer_id': customer_pool})\n",
    "\n",
    "    # For customers in the customer pool, find their sum between the start and end date\n",
    "    totals = data[data['customer_id'].isin(customer_pool) & \n",
    "        (data['order_date'] > start_date) & \n",
    "        (data['order_date']<end_date)\n",
    "    ].groupby('customer_id')['total'].sum().reset_index()\n",
    "    \n",
    "    # Merge with all the customer ids to record all customers who existed before start date\n",
    "    totals = totals.merge(tmp, on = 'customer_id', how = 'right')\n",
    "\n",
    "    # Set the total for any customer who did not have a purchase in the timeframe equal to 0\n",
    "    totals['total'] = totals['total'].fillna(0)\n",
    "    \n",
    "    # Label is based on the threshold\n",
    "    totals['label'] = (totals['total'] > threshold).astype(int)\n",
    "        \n",
    "    # The cutoff time is the start date\n",
    "    totals['cutoff_time'] = pd.to_datetime(start_date)\n",
    "    totals = totals[['customer_id', 'cutoff_time', 'total', 'label']]\n",
    "    \n",
    "    return totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_spending = make_retail_cutoffs_total(pd.datetime(2011, 5, 1), pd.datetime(2011, 6, 1))\n",
    "may_spending.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each customer who appeared in the data before May, we have a label for them for the month of May. When we make features for these labels, we can only use data from _before May_. The `cutoff_time` represents the point at which any data we use must come before and the `label` is based on our threshold of \\$500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_spending['label'].value_counts().plot.bar();\n",
    "plt.title('Label Distribution for May');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an imbalanced classification problem which means that we probably don't want to use accuracy as our metric.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "Instead of plain accuracy, we can measure performance in terms of:\n",
    "\n",
    "* Precision: the percentage of customers predicted to spend more than \\$500 that actually did\n",
    "* Recall: the percentage of customers that actually spent more than \\$500 that were correctly identified\n",
    "* F1 score: the harmonic mean of precision and recall\n",
    "* Receiver Operating Characterisic Area Under the Curve (ROC AUC): a 0 to 1 measure (with 1 being optimal) that measures the performance of a model across a range of thresholds\n",
    "\n",
    "We'll have to establish a baseline for these metrics (which will be a little later) so we know whether machine learning is useful for this task.\n",
    "\n",
    "Next we'll go ahead and make labels for the rest of the year. Keep in mind that this will generate one label for each customer for each month. We're used to thinking of a single label per customer, but since we have the data, we might as well use each customer as a training example as many times as possible (as long as we use valid data each time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_spending = make_retail_cutoffs_total('2011-03-01', '2011-04-01', 500)\n",
    "april_spending = make_retail_cutoffs_total('2011-04-01', '2011-05-01', 500)\n",
    "june_spending = make_retail_cutoffs_total('2011-06-01', '2011-07-01', 500)\n",
    "july_spending = make_retail_cutoffs_total('2011-07-01', '2011-08-01', 500)\n",
    "august_spending = make_retail_cutoffs_total('2011-08-01', '2011-09-01', 500)\n",
    "september_spending = make_retail_cutoffs_total('2011-09-01', '2011-10-01', 500)\n",
    "october_spending = make_retail_cutoffs_total('2011-10-01', '2011-11-01', 500)\n",
    "november_spending = make_retail_cutoffs_total('2011-11-01', '2011-12-01', 500)\n",
    "december_spending = make_retail_cutoffs_total('2011-12-01', '2012-01-01', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([march_spending, april_spending, may_spending, june_spending, july_spending, august_spending, \n",
    "                    september_spending, october_spending, november_spending, december_spending], axis = 0)\n",
    "labels.to_csv('../input/labels.csv')\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have roughly 25,000 labels with ~17% of them positive. The total is very skewed, with several customers recording negative months (they had more cancellations than purchases). By framing this as a classification problem, we don't have to worry about the outlying purchase totals throwing off our model. \n",
    "\n",
    "Just to examine the data, we can plot the total spending distribution by month (with negative totals removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels = labels.copy()\n",
    "plot_labels['month'] = plot_labels['cutoff_time'].dt.month\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "sns.boxplot(x = 'month', y = 'total', \n",
    "            data = plot_labels[(plot_labels['total'] > 0) & (plot_labels['total'] < 1000)]);\n",
    "plt.title('Customer Spending Distribution by Month');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in to one customer to make sure we understand the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.loc[labels['customer_id'] == 12347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.loc[labels['customer_id'] == 12347].set_index('cutoff_time')['total'].plot(figsize = (6, 4), linewidth = 3)\n",
    "plt.xlabel('Date', size = 16); \n",
    "plt.ylabel('Spending', size = 16); \n",
    "plt.title('Monthly Spending for Customer', size = 20);\n",
    "plt.xticks(size = 16); plt.yticks(size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One customer, 8 different labels. It seems like it might be a little difficult to predict this customer's habits given her fluctuating total spending! We'll have to see if Featuretools is up to the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our prediction problem all set. The next step is to start making features we can use in a machine learning model.\n",
    "\n",
    "# Featuretools Implementation\n",
    "\n",
    "The first step in Featuretools is to create an `EntitySet` which will hold all of our data and the relationships between the multiple tables (which we'll create shortly). Initially we'll add the entire `data` as an `entity` to the set. Since data has a `time_index`, we'll add that and specify the variable type of the product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id=\"Online Retail Logs\")\n",
    "\n",
    "# Add the entire data table as an entity\n",
    "es.entity_from_dataframe(\"purchases\",\n",
    "                         dataframe=data,\n",
    "                         index=\"purchases_index\",\n",
    "                         time_index = 'order_date',\n",
    "                         variable_types={'description': ft.variable_types.Text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Entities\n",
    "\n",
    "In order to create new tables out of the original table, we can normalize this `entity`. This creates new tables by creating a unique row for every variable that we pass in, such as the customer or the product.\n",
    "\n",
    "The code below creates a new entity for the `products` where each row contains one product and the columns describe the product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new \"products\" entity\n",
    "es.normalize_entity(new_entity_id=\"products\",\n",
    "                    base_entity_id=\"purchases\",\n",
    "                    index=\"product_id\",\n",
    "                    additional_variables=[\"description\"])\n",
    "\n",
    "es['products'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `first_purchases_time` is automatically created because the `purchases` table has a time index. This represents the first time the product appears in the purchase data. We can use this table to create new features; the products table is a parent of the `purchases` table with the linking variable `product_id`. For each product in `products`, there can be multiple purchases of that product in `purchases`. \n",
    "\n",
    "We'll repeat the process to create tables for both the `customers` and the `orders`. Using `normalize_entity` automatically creates the relationships and time index so we don't have to do that ourselves. If we want to include any other additional variables in the table, we can pass those in. These variables must be unique to the object that we are normalizing for. As an example, each order comes from one country and one customer, so we can include those as additional variables when creating the `orders` table. However, the description is not unique to an order, so that should not be a variable that appears in the orders table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new \"customers\" entity based on the orders entity\n",
    "es.normalize_entity(new_entity_id=\"customers\",\n",
    "                    base_entity_id=\"purchases\",\n",
    "                    index=\"customer_id\")\n",
    "\n",
    "# create a new \"orders\" entity\n",
    "es.normalize_entity(new_entity_id=\"orders\",\n",
    "                    base_entity_id=\"purchases\",\n",
    "                    index=\"order_id\",\n",
    "                    additional_variables=[\"country\", 'cancelled'])\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Synthesis \n",
    "\n",
    "Now that our `EntitySet` is defined with the proper relationships between tables, we can perform [deep feature synthesis](http://www.jmaxkanter.com/static/papers/DSAA_DSM_2015.pdf) to generate 100s or 1000s of features. We can theoretically make features for any entity, but since our objective is to classify customer spending, we'll make features for each customer for each month. \n",
    "\n",
    "The following call will generate features for each customer, resulting in a `feature_matrix` where each row consists of one customer for one month and each column is one feature. \n",
    "\n",
    "## Using cutoff times\n",
    "\n",
    "To ensure the features are valid for the customer and the month, we'll pass in the labels dataframe that has the cutoff time for each customer for each month. Featuretools will make one row for each customer for each month, with the features for each month derived only from data prior to the cutoff time. This is an _extremely useful method_ because it means we don't have to worry about using illegal data to make features. For example, if we were doing this by hand, it would be very easy to create features that use information from the future to make features for months, which is not allowed (well there's nothing stopping us from doing this, but it will lead to very poor models in production). \n",
    "\n",
    "The requirements of the cutoff time dataframe are that the first column contains the ids corresponding to the index of the target entity, and the second column must have the cutoff times. Featuretools then takes care of the rest, for each month only using valid data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, target_entity='customers',\n",
    "                                       cutoff_time = labels, verbose = 2,\n",
    "                                       cutoff_time_in_index = True,\n",
    "                                       chunk_size = len(labels), n_jobs = -1,\n",
    "                                       max_depth = 1)\n",
    "\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to drop the `total` and `label` columns before training because these were passed through from the `cutoff_time` data. (We clearly can't use these for modeling!) We also can remove the `MODE` of the order id and product id. These should not be used for creating features since they are index variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix.drop(columns = ['MODE(purchases.order_id)', 'MODE(purchases.product_id)'])\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we did not generate very many features because we limited the `max_depth` to 1. This means that only 1 aggregation will be stacked at a time. Let's take a look at some of the features. First, we'll zoom back in to a single one of the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.loc[12347, :].sample(10, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to predict spending in November, we can use any data from before November. As we get deeper into the year, we would expect our predictions to get more accurate because we are incorporating more information (we can see the count of purchases increasing as we use more data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_matrix.reset_index(inplace = True)\n",
    "\n",
    "feature_matrix.groupby('time')['COUNT(purchases)'].mean().plot();\n",
    "plt.title('Average Monthly Count of Purchases');\n",
    "plt.ylabel('Purchases Per Customer');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that as we progress through time, we have more purchases per customer to use for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.groupby('time')['SUM(purchases.quantity)'].mean().plot();\n",
    "plt.title('Average Monthly Sum of Purchased Products');\n",
    "plt.ylabel('Total Purchased Products Per Customer');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, as we include more information, our forecasts should improve in accuracy. Therefore, if we are predicting purchase in November, we would expect better performance than predicting purchases in June."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "As a first approximation of useful features, we can see if there are any significant correlations between the features and the `total`. We'll one-hot encode the categorical features first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = pd.get_dummies(feature_matrix).reset_index()\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = feature_matrix.corr().sort_values('total')\n",
    "corrs['total'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs['total'].dropna().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the features have a moderate positive correlation with the `total` (ignoring the `label` for now). The number and total of the purchases is clearly related to the total spending! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(feature_matrix[(feature_matrix['SUM(purchases.total)'] > 0) & (feature_matrix['SUM(purchases.total)'] < 1000)],\n",
    "                  hue = 'label', size = 4, aspect = 3)\n",
    "g.map(sns.kdeplot, 'SUM(purchases.total)')\n",
    "g.add_legend();\n",
    "plt.title('Distribution of Purchases Total by Label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix['month'] = feature_matrix['time'].dt.month\n",
    "sns.violinplot(x = 'month', y = 'NUM_UNIQUE(purchases.order_id)', hue = 'label', figsize = (24, 6),\n",
    "               data = feature_matrix[(feature_matrix['SUM(purchases.total)'] > 0) & (feature_matrix['SUM(purchases.total)'] < 1000)])\n",
    "plt.title('Number of Unique Purchases by Label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary modeling\n",
    "\n",
    "We can now directly use this feature matrix for training and making predictions with a machine learning model. We have a single table of data, so we'll want to split it into separate training and testing sets. For each month, we can do this by first subsetting the data and then using a random split into 30% testing and 70% training. If we want to make predictions for July, we'll subset the data to months before July, then split the data into the training and testing sets. \n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "For a model, we will use the `RandomForestClassifier` as implemented in Scikit-Learn. We'll keep most of the hyperparameters at the default values but increase the number of trees to 1000. This is not an optimized model but should allow us to tell whether or not our solution is better than a baseline estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 1000, \n",
    "                               random_state = 50,\n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below trains and tests for a single month. We pass in the month, and the usable data is subsetted to before the month, and then split into 30% testing and 70% training. The model is trained and makes predictions (both the labels and the probabilities) which we can assess in terms of the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_month(month, feature_matrix, return_probs = False):\n",
    "    \n",
    "    \n",
    "    feature_matrix['month'] = feature_matrix['time'].dt.month\n",
    "    \n",
    "    test_labels = feature_matrix.loc[feature_matrix['month'] == month, 'label']\n",
    "    train_labels = feature_matrix.loc[feature_matrix['month'] < month, 'label']\n",
    "    \n",
    "    # Features\n",
    "    X_train = feature_matrix[feature_matrix['time'].dt.month < month].drop(columns = ['customer_id', 'time',\n",
    "                                                                                     'month', 'label', 'total'])\n",
    "    X_test = feature_matrix[feature_matrix['time'].dt.month == month].drop(columns = ['customer_id', 'time',\n",
    "                                                                                     'month', 'label', 'total'])\n",
    "    feature_names = list(X_train.columns)\n",
    "    \n",
    "    pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    \n",
    "    # Labels\n",
    "    y_train = np.array(train_labels).reshape((-1, ))\n",
    "    y_test = np.array(test_labels).reshape((-1, ))\n",
    "    \n",
    "    print('Training on {} observations.'.format(len(X_train)))\n",
    "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
    "    \n",
    "    # Train \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    p = precision_score(y_test, predictions)\n",
    "    r = recall_score(y_test, predictions)\n",
    "    f = f1_score(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    \n",
    "    print(f'Precision: {round(p, 5)}')\n",
    "    print(f'Recall: {round(r, 5)}')\n",
    "    print(f'F1 Score: {round(f, 5)}')\n",
    "    print(f'ROC AUC: {round(auc, 5)}')\n",
    "    \n",
    "    # Feature importances\n",
    "    fi = pd.DataFrame({'feature': feature_names, 'importance': model.feature_importances_})\n",
    "    \n",
    "    if return_probs:\n",
    "        return fi, probs\n",
    "    \n",
    "    return fi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "june_fi = predict_month(6, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the feature importances using a utility function. These should allow us to see what the model considers useful information for predicting spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_feature_importances\n",
    "\n",
    "norm_june_fi = plot_feature_importances(june_fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are those that are most correlated with the total. This should give us confidence that our machine learning model is learning the important relationships and that the Featuretools features are useful for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Baseline\n",
    "\n",
    "One question we have to ask is how do those numbers compare to an informed baseline. If our model can't beat a simple baseline, then we might want to question our approach or even if machine learning is applicable to the problem. \n",
    "\n",
    "For an informed baseline, let's use the amount the customer spent in the past month to predict how much they will spend in the next month. We can try this for July 2011. For the probability (used for the ROC AUC), we'll divide the previous month's total by the threhold (so a spending of 0 corresponds to 0 probability) and then clip any values to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['month'] = labels['cutoff_time'].dt.month\n",
    "july_labels = labels[labels['month'] == 7]\n",
    "june_labels = labels[labels['month'] == 6]\n",
    "\n",
    "july_labels = july_labels.rename(columns = {'total': 'july_total'})\n",
    "june_labels = june_labels.rename(columns = {'total': 'june_total'})\n",
    "\n",
    "# Merge the current month with the previous\n",
    "july_labels = july_labels.merge(june_labels[['customer_id', 'june_total']], on = 'customer_id', how = 'left')\n",
    "july_labels['june_total'] = july_labels['june_total'].fillna(0)\n",
    "july_labels['predicted_label'] = (july_labels['june_total'] > 500).astype(int)\n",
    "\n",
    "july_labels['probability'] = july_labels['june_total'] / 500\n",
    "    \n",
    "# Set probabilities greater than 1 equal to 1\n",
    "july_labels.loc[july_labels['probability'] > 1, 'probability'] = 1\n",
    "    \n",
    "july_labels.sample(10, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether this is reasonable, we can find the correlation between the previous months total and the current months total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_labels['july_total'].corr(july_labels['june_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a moderate correlation between spending from one month to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('june_total', 'july_total', data = july_labels, fit_reg = False)\n",
    "plt.title('July vs June Spending');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: {:.5f}.'.format(precision_score(july_labels['label'], july_labels['predicted_label'])))\n",
    "print('Recall: {:.5f}.'.format(recall_score(july_labels['label'], july_labels['predicted_label'])))\n",
    "print('F1 Score: {:.5f}.'.format(f1_score(july_labels['label'], july_labels['predicted_label'])))\n",
    "print('ROC AUC Score: {:.5f}.'.format(roc_auc_score(july_labels['label'], july_labels['probability'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare this performance to that from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_fi, july_probs = predict_month(7, feature_matrix, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a classifier, the most important metric is the ROC AUC because that accounts for performance across all possible thresholds. We can adjust the threshold to maximize the Recall/Precision/F1 Score depending on our preferences.\n",
    "\n",
    "To make sure that our model is really outperforming the baseline, we can plot the Receiver Operating Characteristic Curve for the two sets of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false positive rates and true positive rates\n",
    "base_fpr, base_tpr, _ = roc_curve(july_labels['label'], july_labels['probability'])\n",
    "model_fpr, model_tpr, _ = roc_curve(feature_matrix[feature_matrix['month'] == 7]['label'], july_probs)\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.rcParams['font.size'] = 16\n",
    "# Plot both curves\n",
    "plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "plt.legend();\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the metrics and this plot, we can say that our model does indeed outperform the informed baseline guess. Machine learning, and the features from Featuretools, yield us a better solution than using domain knowledge. \n",
    "\n",
    "__If we were an online retailer currently using an informed guess for advertising, machine learning could make our advertising campaigns more efficient.__\n",
    "\n",
    "Let's take all of the code for comparing the baseline to the model and put it in a single function. First we need to calculate the informed baseline in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informed_baseline(month_number, threshold = 500):\n",
    "    \"\"\"Calculate an informed baseline for a given month. \n",
    "    The informed baseline is guessing the previous month's spending\n",
    "    for the next month. The probability is assessed by dividing\n",
    "    the previous month's total by the threshold and setting\n",
    "    any values greater than 1 to 1.\"\"\"\n",
    "    \n",
    "    # Subset to the months\n",
    "    month = labels[labels['month'] == month_number]\n",
    "    previous_month = labels[labels['month'] == (month_number - 1)]\n",
    "    \n",
    "    previous_month = previous_month.rename(columns = {'total': 'previous_total'})\n",
    "\n",
    "    # Merge the current month with the previous month\n",
    "    month = month.merge(previous_month[['customer_id', 'previous_total']], on = 'customer_id', how = 'left')\n",
    "    \n",
    "    month['previous_total'] = month['previous_total'].fillna(0)\n",
    "    month['probability'] = month['previous_total'] / threshold\n",
    "    \n",
    "    # Set probabilities greater than 1 equal to 1\n",
    "    month.loc[month['probability'] > 1, 'probability'] = 1\n",
    "    \n",
    "    # Make the predicted label\n",
    "    month['prediction'] = (month['previous_total'] > threshold).astype(int)\n",
    "    \n",
    "    print('Precision: {:.5f}.'.format(precision_score(month['label'], month['prediction'])))\n",
    "    print('Recall: {:.5f}.'.format(recall_score(month['label'], month['prediction'])))\n",
    "    print('F1 Score: {:.5f}.'.format(f1_score(month['label'], month['prediction'])))\n",
    "    print('ROC AUC Score: {:.5f}.'.format(roc_auc_score(month['label'], month['probability'])))\n",
    "    \n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(month, feature_matrix):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "    print('Baseline Performance')\n",
    "    baseline = informed_baseline(month)\n",
    "    \n",
    "    print('\\nModel Performance')\n",
    "    fi, probs = predict_month(month, feature_matrix, return_probs=True)\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(baseline['label'], baseline['probability'])\n",
    "    model_fpr, model_tpr, _ = roc_curve(feature_matrix[feature_matrix['month'] == month]['label'], probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(6, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test December, when theoretically our model should do the best because it is training on the most data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(12, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a slightly better ROC AUC. It's possible that the data does not stay consistent over the couse of the year so using more data might not necessarily create a better model. In other words, consumer behavior can shift (due to seasonality) so the older data might not be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Deep Feature Synthesis\n",
    "\n",
    "We saw that even a basic implementation of Featuretools can yield a set of useful features. Next, we want to ask if we can achieve even better performance by generating a richer set of features. We can expand the capabilities of Featuretools by specifying the primitives we use, increasing the maximum depth of stacked features, writing our own custom primitives, identifying interesting values, and using seed features. For an explanation of all these concepts, refer to the [Featuretools documentation.](https://docs.featuretools.com/guides/tuning_dfs.html)\n",
    "\n",
    "In the code cell below, we again use Featuretools but this time specify a few more primitives and increase the maximum depth. This might create some unnecessary features, but we can then use feature selection to remove them. Having too many features is a better problem than having too few! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, target_entity='customers',\n",
    "                                       agg_primitives = ['std', 'max', 'min', 'mode',\n",
    "                                                         'mean', 'skew', 'last', 'avg_time_between'],\n",
    "                                       trans_primitives = ['cum_sum', 'cum_mean', 'day', \n",
    "                                                           'month', 'hour', 'weekend'],\n",
    "                                       n_jobs = -1, chunk_size = len(labels), max_depth = 2,\n",
    "                                       cutoff_time = labels,\n",
    "                                       verbose = 1)\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use these features for modeling, we need to one-hot encode them. Because some of the features are built from the id variables, one-hot encoding them will create far too many features. We'll have to be careful about increasing the number of columns too greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that the most important feature is whether the most common country for the order is the United Kingdom. This suggests there may a difference in order that come from the United Kingdom versus orders from other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = es['orders'].df\n",
    "order_products = es['order_products'].df\n",
    "order_products = order_products.merge(orders[['order_id', 'country']], \n",
    "                                      on = 'order_id', how = 'left')\n",
    "\n",
    "orders_by_country = order_products.groupby('country')['total'].agg(['sum', 'mean', 'count'])\n",
    "orders_by_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_by_country['count'].sort_values().plot.bar(color = 'green', \n",
    "                                    figsize = (10, 8));\n",
    "plt.title('Number of Orders by Country');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_by_country['mean'].sort_values().plot.bar(color = 'red', \n",
    "                                    figsize = (12, 8));\n",
    "plt.title('Mean of Order Total by Country', size = 22);\n",
    "plt.ylabel('Mean Order Total ($)', size = 18); plt.xlabel('Country', size = 16)\n",
    "plt.xticks(size = 16); plt.yticks(size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some minor feature selection and see if the performance improves. The following call \n",
    "removes:\n",
    "\n",
    "* One out of every pair of columns that have a perfect correlation (all values are equal)\n",
    "* Any features with more than 80% missing values \n",
    "* Any features with only a single unique value\n",
    "* One out of every pair of columns with a correlation greater than 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = feature_matrix_enc['time']\n",
    "feature_matrix_selected = feature_selection(feature_matrix_enc.drop(columns = ['time']),\n",
    "                                                                    missing_threshold=80, correlation_threshold=0.9)\n",
    "feature_matrix_selected['time'] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Primitives\n",
    "\n",
    "We saw that an informed baseline guess just using the previous month's total yielded a decent solution (although worse than machine learning). Therefore, we might want to consider using this as a feature in our model. To build this feature (which will actually find the total of any numeric column for the previous month) we can write a custom primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.datetime(2011, 6, 1)\n",
    "ct.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_agg_primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_previous_month(numeric, datetime, time):\n",
    "    df = pd.DataFrame({'value': numeric, 'time': datetime})\n",
    "    previous_month = time.month - 1\n",
    "    \n",
    "    df = df[df['time'].dt.month == previous_month]\n",
    "    total = df['value'].sum()\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_previous = make_agg_primitive(total_previous_month, input_types = [ft.variable_types.Numeric,\n",
    "                                                                         ft.variable_types.Datetime],\n",
    "                                    return_type = ft.variable_types.Numeric, \n",
    "                                    uses_calc_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, target_entity='customers',\n",
    "                                       cutoff_time = labels, \n",
    "                                       cutoff_time_in_index = True, \n",
    "                                       agg_primitives = [total_previous], \n",
    "                                       trans_primitives = [], chunk_size = 100,\n",
    "                                       verbose = 1, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.drop_duplicates(inplace = True)\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_fi = predict_month(12, feature_matrix_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection slightly improved the models performance compared to the original metrics (shown below):\n",
    "\n",
    "    Precision: 0.27073\n",
    "    Recall: 0.50314\n",
    "    F1 Score: 0.35204\n",
    "    ROC AUC: 0.86048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Based on Feature Importances\n",
    "\n",
    "Another method we can use for feature selection is to remove any features that have zero importance. In a decision tree based model, removing these features will have no effect on performance and is hence a safe option for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_features = december_fi.loc[december_fi['importance'] == 0, 'feature']\n",
    "print(f'{len(zero_features)} features with no importance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_selected = feature_matrix_selected[[x for x in feature_matrix_selected if x not in zero_features]]\n",
    "feature_matrix_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Deep Feature Synthesis\n",
    "\n",
    "We can specify different primitives to deep feature synthesis in order to generate different features. Let's try making a new feature matrix with specified primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the new feature matrix, we need to one-hot encode it. We can also use feature selection because that improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_enc = pd.get_dummies(feature_matrix)\n",
    "\n",
    "for col in feature_matrix_enc:\n",
    "    if feature_matrix_enc[col].dtype == 'bool':\n",
    "        feature_matrix_enc[col] = feature_matrix_enc[col].astype(np.uint8)\n",
    "\n",
    "feature_matrix_selected = feature_selection(feature_matrix_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_selected.reset_index(inplace = True)\n",
    "\n",
    "# Add the time\n",
    "feature_matrix_selected['time'] = list(labels['cutoff_time'])\n",
    "\n",
    "june_fi = predict_month(6, feature_matrix_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous metrics for June were:\n",
    "\n",
    "    Precision: 0.51842\n",
    "    Recall: 0.46244\n",
    "    F1 Score: 0.48883\n",
    "    ROC AUC: 0.78358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_june_fi = plot_feature_importances(june_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_fi = predict_month(12, feature_matrix_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = informed_baseline(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with more features from Featuretools again significantly outperforms the baseline. To improve the precision, recall, and consequently the F1 score, we can tune the threshold of predictions made by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall Curve\n",
    "\n",
    "We can use the precision recall curve to identify the ideal threshold for our model. For example, we might care more about identifying the customers likely to spend more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 12\n",
    "# Find the probability\n",
    "fi, probs = predict_month(month, feature_matrix_selected, \n",
    "                          return_probs = True)\n",
    "\n",
    "precision, recall, t = precision_recall_curve(labels.loc[labels['cutoff_time'].dt.month == month, 'label'], \n",
    "                                              probs)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.5,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.5,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision vs. Recall Curve\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.text(precision[::10], recall[::10], s = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(month):\n",
    "    \"Show the precision vs recall curve for a month\"\n",
    "    \n",
    "    # Find the probability\n",
    "    fi, probs = predict_month(month, feature_matrix_selected, \n",
    "                              return_probs = True)\n",
    "    \n",
    "    precision, recall, t = precision_recall_curve(labels.loc[labels['cutoff_time'].dt.month == month, 'label'], \n",
    "                                                  probs)\n",
    "    \n",
    "    plt.step(recall, precision, color='b', alpha=0.5,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.5,\n",
    "                     color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision vs. Recall Curve\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this plot to select an appropriate threshold. For example, we may care more about identifying customers who will spend more than \\$500 than about false positive so we choose a threshold that results in high recall but low precision. Conversely, we may want to limit false positives even if that means missing some potential high-spending customers so we would try for a higher level of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
